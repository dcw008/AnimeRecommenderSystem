{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true,
    "scrolled": false
   },
   "source": [
    "import csv\n",
    "from collections import defaultdict\n",
    "\n",
    "toJson = open('anime.json', 'w')\n",
    "count = 0\n",
    "toJson.write('[')\n",
    "with open('anime.csv') as csvDataFile:\n",
    "    csvReader = csv.reader(csvDataFile)\n",
    "    for row in csvReader:\n",
    "        if row[0] == 'anime_id':\n",
    "            continue\n",
    "        \n",
    "        \n",
    "        genre_list = row[2].split(',')\n",
    "        genres = '['\n",
    "        for g in range(len(genre_list)):\n",
    "            genre = genre_list[g].replace(\" \", \"\")\n",
    "            genres += '\"'\n",
    "            genres += genre\n",
    "            if g != len(genre_list)-1:\n",
    "                genres += '\",'\n",
    "            else:\n",
    "                genres += '\"]'\n",
    "                \n",
    "        rating = row[5]\n",
    "        if rating == '':\n",
    "            rating = -1\n",
    "        \n",
    "        if (count != 0):\n",
    "            toJson.write(',\\n')\n",
    "        \n",
    "        toJson.write('{ \"anime_id\" : \"' + str(row[0]) + '\", \"name\" : \"' + str(row[1]) + '\", \"genre\" : '\n",
    "              + str(genres) + ', \"type\" : \"' + str(row[3]) + '\", \"episodes\" : \"'\n",
    "              + str(row[4]) + '\", \"rating\" : ' + str(rating) + ', \"members\" : ' + str(row[6]) + '}')\n",
    "        \n",
    "        count += 1\n",
    "    \n",
    "toJson.write(']')\n",
    "toJson.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# import data\n",
    "\n",
    "import json\n",
    "\n",
    "rating = json.load(open('rating_200k.json'))\n",
    "animedata = json.load(open('anime.json'))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Make a train / validation set\n",
    "\n",
    "# Filter rating of '-1' in rating dataset\n",
    "\n",
    "rating_filtered = []\n",
    "for entry in rating:\n",
    "    if (entry['rating'] != '-1'):\n",
    "        rating_filtered.append(entry)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Approach 2 (scrambled dataset)\n",
    "\n",
    "import random\n",
    "\n",
    "def scrambled(orig):\n",
    "    dest = orig[:]\n",
    "    random.shuffle(dest)\n",
    "    return dest\n",
    "\n",
    "rating_scrambled = scrambled(rating_filtered)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Approach 3 (evenly distributed dataset)\n",
    "\n",
    "def build_rating_dataset():\n",
    "\n",
    "    rating_toModify = rating_filtered[:]\n",
    "\n",
    "    current_user_id = 1\n",
    "    rating_3 = []\n",
    "\n",
    "    checknumber = 150000\n",
    "\n",
    "    while(len(rating_toModify) > 3000):\n",
    "\n",
    "        for j in range(0,len(rating_toModify)-1):\n",
    "\n",
    "            if j >= len(rating_toModify)-1:\n",
    "                break\n",
    "\n",
    "            this_rating = rating_toModify[j]\n",
    "            current_user_id_str = str(current_user_id)\n",
    "\n",
    "            if this_rating['user_id'] == current_user_id_str:\n",
    "\n",
    "                rating_3.append(this_rating)\n",
    "                rating_toModify.pop(j)\n",
    "                current_user_id += 1\n",
    "\n",
    "            if int(this_rating['user_id']) > current_user_id:\n",
    "                current_user_id += 1\n",
    "\n",
    "\n",
    "\n",
    "        if current_user_id >= 2012:\n",
    "            current_user_id = 1\n",
    "\n",
    "    remaining = rating_toModify[:]\n",
    "    rating_3 = rating_3 + remaining\n",
    "    rating_3 = rating_3[:150000]\n",
    "    \n",
    "    return rating_3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "rating_3 = build_rating_dataset()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# separate train/validation by half\n",
    "\n",
    "data_size = 75000\n",
    "training_set = rating_3[:data_size]\n",
    "validation_set = rating_3[data_size:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# constructing latent factor model\n",
    "\n",
    "beta_u = defaultdict(float)\n",
    "beta_i = defaultdict(float)\n",
    "alpha = defaultdict(float)\n",
    "\n",
    "\n",
    "# This function constructs beta_u, beta_i, alpha for latent factor model\n",
    "\n",
    "def construct_latent_factor_model():\n",
    "\n",
    "    rating_by_user = defaultdict(list)    # list of animes with rating that each user watched\n",
    "    rating_by_anime = defaultdict(list)    # list of dictionary with anime as keys, and containing user and ratings\n",
    "    \n",
    "    for entry in training_set:\n",
    "\n",
    "        anime_dict = {}\n",
    "        if (entry['rating'] != '-1'):\n",
    "            anime_dict['anime_id'] = entry['anime_id']\n",
    "            anime_dict['rating'] = entry['rating']\n",
    "            rating_by_user[entry['user_id']].append(anime_dict)\n",
    "\n",
    "        user_dict = {}\n",
    "        if (entry['rating'] != '-1'):\n",
    "            user_dict['rating'] = entry['rating']\n",
    "            user_dict['user_id'] = entry['user_id'] \n",
    "            rating_by_anime[entry['anime_id']].append(user_dict)\n",
    "            \n",
    "\n",
    "            \n",
    "    # calculating average ratings by user        \n",
    "    \n",
    "    average_rating_by_user = defaultdict(float)\n",
    "    \n",
    "    for user in rating_by_user:\n",
    "\n",
    "        animes = rating_by_user[user]\n",
    "        total_rating = 0\n",
    "        count = 0\n",
    "\n",
    "        for anime in animes:    \n",
    "            total_rating += float(anime['rating'])\n",
    "            count += 1\n",
    "\n",
    "        if count != 0:\n",
    "            average_rating_by_user[user] = total_rating / count\n",
    "            \n",
    "\n",
    "    # constructing beta_u\n",
    "    \n",
    "    total_user_rating = 0\n",
    "    user_count = 0\n",
    "    \n",
    "    for user in average_rating_by_user:\n",
    "        total_user_rating += average_rating_by_user[user]\n",
    "        user_count += 1\n",
    "\n",
    "    total_average_rating_byuser = total_user_rating / user_count\n",
    "\n",
    "    for user in average_rating_by_user:\n",
    "        beta_u[user] = average_rating_by_user[user] - total_average_rating_byuser\n",
    "        \n",
    "        \n",
    "\n",
    "    # Calculating average rating by anime\n",
    "    \n",
    "    anime_average_rating = defaultdict(float)      # average rating of each anime\n",
    "\n",
    "    for entry in animedata:\n",
    "        if (entry['rating'] != -1 and entry['rating'] != 0):\n",
    "            anime_average_rating[entry['anime_id']] = entry['rating']\n",
    "            \n",
    "            \n",
    "    # Calculating beta_i\n",
    "\n",
    "    total_anime_rating = 0\n",
    "    anime_count = 0\n",
    "    for anime in anime_average_rating:\n",
    "        total_anime_rating += anime_average_rating[anime]\n",
    "        anime_count += 1\n",
    "\n",
    "    total_average_rating_byanime = total_anime_rating / anime_count\n",
    "\n",
    "    for anime in anime_average_rating:\n",
    "        beta_i[anime] = anime_average_rating[anime] - total_average_rating_byanime\n",
    "      \n",
    "    \n",
    "    # alpha\n",
    "    \n",
    "    alpha = anime_average_rating \n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# construct_latent_factor_model()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# TODO: feature for latent factor model\n",
    "\n",
    "# def feature_train(this_anime):\n",
    "#     a = alpha[this_anime]\n",
    "#     bi = beta_i[this_anime]\n",
    "#     feat = [1]\n",
    "#     for entry in training_set:\n",
    "#         bu = beta_u[entry['user_id']]\n",
    "#         feat.append(a+bi+beta_u[user])\n",
    "        \n",
    "#     return feat\n",
    "        \n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# X = [feature_train(anime) for anime in beta_i]\n",
    "# y = [float(d['rating']) for d in training_set]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Collaborative Filtering + Regression for rating prediction\n",
    "# Collaborative Filtering for watch prediction (in case we can't figure out how to do rating prediction)\n",
    "# Basic model for latent factor model\n",
    "# How to optimize\n",
    "\n",
    "### Graph\n",
    "# rating according to genre\n",
    "# rating according to types (Movie/OVA/TV Series)\n",
    "# rating according to number of members\n",
    "# Most popular word occuring in title\n",
    "# Average number of members by genres\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Collaborative Filtering + Regression for rating prediction\n",
    "# Collaborative Filtering for watch prediction (in case we can't figure out how to do rating prediction)\n",
    "# Basic model for latent factor model\n",
    "# How to optimize"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Rating prediction based on collaborative filtering + regression\n",
    "\n",
    "\n",
    "def get_anime_users():\n",
    "    #first get a dictionary of key: business user: set\n",
    "    anime_user_dict = {}\n",
    "    for review in training_set:\n",
    "        anime = review['anime_id']\n",
    "        user = review['user_id']\n",
    "        if anime in anime_user_dict:\n",
    "            user_set = anime_user_dict[anime]\n",
    "            user_set.add(user)\n",
    "        else:\n",
    "            user_set = set()\n",
    "            user_set.add(user)\n",
    "            anime_user_dict[anime] = user_set\n",
    "    return anime_user_dict\n",
    "\n",
    "def get_user_anime():\n",
    "    #first get a dictionary of key: business user: set\n",
    "    user_anime_dict = {}\n",
    "    for review in training_set:\n",
    "        anime = review['anime_id']\n",
    "        user = review['user_id']\n",
    "        if user in user_anime_dict:\n",
    "            anime_set = user_anime_dict[user]\n",
    "            anime_set.add(anime)\n",
    "        else:\n",
    "            anime_set = set()\n",
    "            anime_set.add(anime)\n",
    "            user_anime_dict[user] = anime_set\n",
    "    return user_anime_dict\n",
    "\n",
    "\n",
    "\n",
    "def jaccard_sim_user(check_user, check_anime):\n",
    "    #given a business, find the most similar business\n",
    "    max_sim = 0.0\n",
    "#     count = 0\n",
    "\n",
    "    if check_anime not in anime_users_dict: return False\n",
    "    else:\n",
    "        users = anime_users_dict[check_anime]\n",
    "        for user in users:\n",
    "            if user == check_user: continue\n",
    "            if check_user not in user_anime_dict: continue\n",
    "            current_user_anime = user_anime_dict[user]\n",
    "            check_user_anime = user_anime_dict[check_user]\n",
    "            intersect = current_user_anime.intersection(check_user_anime)\n",
    "            union = current_user_anime.union(check_user_anime)\n",
    "            # print(intersect)\n",
    "            # print(union)\n",
    "            similarity = float(len(intersect))/len(union)\n",
    "            if similarity > max_sim:\n",
    "                max_sim = similarity\n",
    "            #max_sim += similarity\n",
    "#             count += 1\n",
    "\n",
    "#      print(max_sim)\n",
    "    return max_sim\n",
    "\n",
    "#     if (max_sim > 0.059):\n",
    "#         return True\n",
    "#     else:\n",
    "#         return False\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# call function to build anime_user_dict and user_anime_dict\n",
    "\n",
    "anime_users_dict = get_anime_users()\n",
    "user_anime_dict = get_user_anime()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import numpy\n",
    "\n",
    "# feature based on collaborative filtering\n",
    "def feature(u,a):\n",
    "    feat = [1]\n",
    "    #feat.append(1 if jaccard_sim_user(u,a) > 0.01 else 0)\n",
    "    feat.append(jaccard_sim_user(u,a))\n",
    "#     if (similarity(u,a)):\n",
    "#         feat.append(1)\n",
    "#     else:\n",
    "#         feat.append(0)\n",
    "    return feat"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "X_train = [feature(d['user_id'],d['anime_id']) for d in training_set]\n",
    "y_train = [float(d['rating']) for d in training_set]\n",
    "X_validation = [feature(d['user_id'],d['anime_id']) for d in validation_set]\n",
    "y_validation = [float(d['rating']) for d in validation_set]\n",
    "theta, residuals, rank, s = numpy.linalg.lstsq(X_train,y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 7.70948912,  1.53688363])"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "theta"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import math\n",
    "\n",
    "def mse(X, y, theta, size):\n",
    "    MSSum = 0.0\n",
    "    for i in range(0,size):\n",
    "        MSSum += numpy.square(int(y[i]) - numpy.dot(X[i], theta))\n",
    "    return MSSum / size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation MSE is 2.29699162412\n",
      "Training MSE is 2.2622388855\n",
      "variance is 2.30704351556\n",
      "\n",
      "RMSE is 1.5155829321147043\n"
     ]
    }
   ],
   "source": [
    "# Calculating MSE and variance\n",
    "\n",
    "print(\"Validation MSE is \" + str(mse(X_validation,y_validation, theta, len(X_validation))))\n",
    "print(\"Training MSE is \" + str(mse(X_train,y_train, theta, len(X_train))))\n",
    "print(\"variance is \" + str(numpy.var([int(d) for d in y_validation])))\n",
    "\n",
    "print(\"\\nRMSE is \"+ str(math.sqrt(mse(X_validation,y_validation, theta, len(X_validation)))))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Watch prediction based on collaborative filtering\n",
    "\n",
    "\n",
    "import random\n",
    "\n",
    "anime_id_set = set()\n",
    "user_id_set = set()\n",
    "for l in rating_3:\n",
    "    anime_id_set.add(l['anime_id'])\n",
    "    user_id_set.add(l['user_id'])\n",
    "    \n",
    "visited_pair = []\n",
    "for l in validation_set:\n",
    "    visited_pair.append((l['user_id'], l['anime_id']))\n",
    "anime_id_list = list(anime_id_set)\n",
    "user_id_list = list(user_id_set)\n",
    "visited_pair = set(visited_pair)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# Build random pairs \n",
    "\n",
    "random_pair = []\n",
    "count = 0\n",
    "\n",
    "while(count < 75000):\n",
    "    randomIndex1 = random.randint(0, len(anime_id_set)-1)\n",
    "    randomIndex2 = random.randint(0, len(user_id_set)-1)\n",
    "    userid = user_id_list[randomIndex2]\n",
    "    animeid = anime_id_list[randomIndex1]\n",
    "    \n",
    "    if (userid,animeid) not in visited_pair:\n",
    "        temp_dict = {}\n",
    "        temp_dict['user_id'] = userid\n",
    "        temp_dict['anime_id'] = animeid\n",
    "    \n",
    "        random_pair.append(temp_dict)\n",
    "        count += 1\n",
    "        \n",
    "        \n",
    "# Combine random pairs with validation set to make complete validation set\n",
    "\n",
    "complete_validation_set = validation_set + random_pair"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Watch prediction\n",
    "\n",
    "def watch_prediction():\n",
    "    \n",
    "    true_pos = 0\n",
    "    true_neg = 0\n",
    "    \n",
    "    for l in validation_set:\n",
    "        u,a = l['user_id'], l['anime_id']\n",
    "        if jaccard_sim_user(u,a):\n",
    "            true_pos += 1\n",
    "            \n",
    "    for l in random_pair:\n",
    "        u,a = l['user_id'], l['anime_id']\n",
    "        if not jaccard_sim_user(u,a):\n",
    "            true_neg += 1\n",
    "            \n",
    "    accuracy = (true_pos + true_neg) / len(complete_validation_set)\n",
    "    print(\"Accuracy is \", accuracy)\n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy is  0.65856\n"
     ]
    }
   ],
   "source": [
    "watch_prediction()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# To-do List\n",
    "\n",
    "# Finish latent factor model with regresison\n",
    "# Try using both jaccard similarity and latent factor model\n",
    "# Writeup\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
