{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true,
    "scrolled": false
   },
   "source": [
    "import csv\n",
    "from collections import defaultdict\n",
    "\n",
    "toJson = open('anime.json', 'w')\n",
    "count = 0\n",
    "toJson.write('[')\n",
    "with open('anime.csv') as csvDataFile:\n",
    "    csvReader = csv.reader(csvDataFile)\n",
    "    for row in csvReader:\n",
    "        if row[0] == 'anime_id':\n",
    "            continue\n",
    "        \n",
    "        \n",
    "        genre_list = row[2].split(',')\n",
    "        genres = '['\n",
    "        for g in range(len(genre_list)):\n",
    "            genre = genre_list[g].replace(\" \", \"\")\n",
    "            genres += '\"'\n",
    "            genres += genre\n",
    "            if g != len(genre_list)-1:\n",
    "                genres += '\",'\n",
    "            else:\n",
    "                genres += '\"]'\n",
    "                \n",
    "        rating = row[5]\n",
    "        if rating == '':\n",
    "            rating = -1\n",
    "        \n",
    "        if (count != 0):\n",
    "            toJson.write(',\\n')\n",
    "        \n",
    "        toJson.write('{ \"anime_id\" : \"' + str(row[0]) + '\", \"name\" : \"' + str(row[1]) + '\", \"genre\" : '\n",
    "              + str(genres) + ', \"type\" : \"' + str(row[3]) + '\", \"episodes\" : \"'\n",
    "              + str(row[4]) + '\", \"rating\" : ' + str(rating) + ', \"members\" : ' + str(row[6]) + '}')\n",
    "        \n",
    "        count += 1\n",
    "    \n",
    "toJson.write(']')\n",
    "toJson.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# import data\n",
    "\n",
    "import json\n",
    "\n",
    "rating = json.load(open('rating_200k.json', encoding='utf8'))\n",
    "animedata = json.load(open('anime.json', encoding='utf8'))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Make a train / validation set\n",
    "\n",
    "# Filter rating of '-1' in rating dataset\n",
    "\n",
    "rating_filtered = []\n",
    "for entry in rating:\n",
    "    if (entry['rating'] != '-1'):\n",
    "        rating_filtered.append(entry)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Approach 2 (scrambled dataset)\n",
    "\n",
    "import random\n",
    "\n",
    "def scrambled(orig):\n",
    "    dest = orig[:]\n",
    "    random.shuffle(dest)\n",
    "    return dest\n",
    "\n",
    "rating_scrambled = scrambled(rating_filtered)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Approach 3 (evenly distributed dataset)\n",
    "\n",
    "def build_rating_dataset():\n",
    "\n",
    "    rating_toModify = rating_filtered[:]\n",
    "\n",
    "    current_user_id = 1\n",
    "    rating_3 = []\n",
    "\n",
    "    checknumber = 150000\n",
    "\n",
    "    while(len(rating_toModify) > 3000):\n",
    "\n",
    "        for j in range(0,len(rating_toModify)-1):\n",
    "\n",
    "            if j >= len(rating_toModify)-1:\n",
    "                break\n",
    "\n",
    "            this_rating = rating_toModify[j]\n",
    "            current_user_id_str = str(current_user_id)\n",
    "\n",
    "            if this_rating['user_id'] == current_user_id_str:\n",
    "\n",
    "                rating_3.append(this_rating)\n",
    "                rating_toModify.pop(j)\n",
    "                current_user_id += 1\n",
    "\n",
    "            if int(this_rating['user_id']) > current_user_id:\n",
    "                current_user_id += 1\n",
    "\n",
    "\n",
    "\n",
    "        if current_user_id >= 2012:\n",
    "            current_user_id = 1\n",
    "\n",
    "    remaining = rating_toModify[:]\n",
    "    rating_3 = rating_3 + remaining\n",
    "    rating_3 = rating_3[:150000]\n",
    "    \n",
    "    return rating_3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "rating_3 = build_rating_dataset()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# separate train/validation by half\n",
    "\n",
    "data_size = 70000\n",
    "training_set = rating_3[:data_size]\n",
    "validation_set = rating_3[data_size:data_size*2]\n",
    "test_set = rating_3[data_size*2:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# constructing latent factor model\n",
    "\n",
    "beta_u = defaultdict(float)\n",
    "beta_i = defaultdict(float)\n",
    "alpha = defaultdict(float)\n",
    "\n",
    "\n",
    "# This function constructs beta_u, beta_i, alpha for latent factor model\n",
    "\n",
    "def construct_latent_factor_model():\n",
    "\n",
    "    rating_by_user = defaultdict(list)    # list of animes with rating that each user watched\n",
    "    rating_by_anime = defaultdict(list)    # list of dictionary with anime as keys, and containing user and ratings\n",
    "    \n",
    "    for entry in training_set:\n",
    "\n",
    "        anime_dict = {}\n",
    "        if (entry['rating'] != '-1'):\n",
    "            anime_dict['anime_id'] = entry['anime_id']\n",
    "            anime_dict['rating'] = entry['rating']\n",
    "            rating_by_user[entry['user_id']].append(anime_dict)\n",
    "\n",
    "        user_dict = {}\n",
    "        if (entry['rating'] != '-1'):\n",
    "            user_dict['rating'] = entry['rating']\n",
    "            user_dict['user_id'] = entry['user_id'] \n",
    "            rating_by_anime[entry['anime_id']].append(user_dict)\n",
    "            \n",
    "\n",
    "            \n",
    "    # calculating average ratings by user        \n",
    "    \n",
    "    average_rating_by_user = defaultdict(float)\n",
    "    \n",
    "    for user in rating_by_user:\n",
    "\n",
    "        animes = rating_by_user[user]\n",
    "        total_rating = 0\n",
    "        count = 0\n",
    "\n",
    "        for anime in animes:    \n",
    "            total_rating += float(anime['rating'])\n",
    "            count += 1\n",
    "\n",
    "        if count != 0:\n",
    "            average_rating_by_user[user] = total_rating / count\n",
    "            \n",
    "\n",
    "    # constructing beta_u\n",
    "    \n",
    "    total_user_rating = 0\n",
    "    user_count = 0\n",
    "    \n",
    "    for user in average_rating_by_user:\n",
    "        total_user_rating += average_rating_by_user[user]\n",
    "        user_count += 1\n",
    "\n",
    "    total_average_rating_byuser = total_user_rating / user_count\n",
    "\n",
    "    for user in average_rating_by_user:\n",
    "        beta_u[user] = average_rating_by_user[user] - total_average_rating_byuser\n",
    "        \n",
    "        \n",
    "\n",
    "    # Calculating average rating by anime\n",
    "    \n",
    "    anime_average_rating = defaultdict(float)      # average rating of each anime\n",
    "\n",
    "    for entry in animedata:\n",
    "        if (entry['rating'] != -1 and entry['rating'] != 0):\n",
    "            anime_average_rating[entry['anime_id']] = entry['rating']\n",
    "            \n",
    "            \n",
    "    # Calculating beta_i\n",
    "\n",
    "    total_anime_rating = 0\n",
    "    anime_count = 0\n",
    "    for anime in anime_average_rating:\n",
    "        total_anime_rating += anime_average_rating[anime]\n",
    "        anime_count += 1\n",
    "\n",
    "    total_average_rating_byanime = total_anime_rating / anime_count\n",
    "\n",
    "    for anime in anime_average_rating:\n",
    "        beta_i[anime] = anime_average_rating[anime] - total_average_rating_byanime\n",
    "      \n",
    "    \n",
    "    # alpha\n",
    "    \n",
    "    alpha = anime_average_rating \n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "reviewsPerUser = defaultdict(list)\n",
    "reviewsPerAnime = defaultdict(list)\n",
    "for r in training_set:\n",
    "    reviewsPerUser[r['user_id']].append(r)\n",
    "    reviewsPerAnime[r['anime_id']].append(r)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation MSE (average only) = 2.332054253877099\n"
     ]
    }
   ],
   "source": [
    "trainRatings = [int(r['rating']) for r in training_set]\n",
    "globalAverage = sum(trainRatings) * 1.0 / len(trainRatings)\n",
    "\n",
    "validMSE = 0\n",
    "for r in validation_set:\n",
    "    se = (int(r['rating']) - globalAverage)**2\n",
    "    validMSE += se\n",
    "\n",
    "validMSE /= len(validation_set)\n",
    "\n",
    "print(\"Validation MSE (average only) = \" + str(validMSE))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 135,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "betaU = {}\n",
    "betaI = {}\n",
    "for u in reviewsPerUser:\n",
    "    betaU[u] = 0\n",
    "\n",
    "for i in reviewsPerAnime:\n",
    "    betaI[i] = 0\n",
    "\n",
    "alpha = globalAverage\n",
    "\n",
    "def resetBeta():\n",
    "    global betaU\n",
    "    global betaI\n",
    "    global alpha\n",
    "    betaU = {}\n",
    "    betaI = {}\n",
    "    for u in reviewsPerUser:\n",
    "        betaU[u] = 0\n",
    "\n",
    "    for i in reviewsPerAnime:\n",
    "        betaI[i] = 0\n",
    "\n",
    "    alpha = globalAverage\n",
    "\n",
    "def iterate(lamb):\n",
    "    newAlpha = 0\n",
    "    for r in training_set:\n",
    "        newAlpha += int(r['rating']) - (betaU[r['user_id']] + betaI[r['anime_id']])\n",
    "    alpha = newAlpha / len(training_set)\n",
    "    for u in reviewsPerUser:\n",
    "        newBetaU = 0\n",
    "        for r in reviewsPerUser[u]:\n",
    "            newBetaU += int(r['rating']) - (alpha + betaI[r['anime_id']])\n",
    "        betaU[u] = newBetaU / (lamb + len(reviewsPerUser[u]))\n",
    "    for i in reviewsPerAnime:\n",
    "        newBetaI = 0\n",
    "        for r in reviewsPerAnime[i]:\n",
    "            newBetaI += int(r['rating']) - (alpha + betaU[r['user_id']])\n",
    "        betaI[i] = newBetaI / (lamb + len(reviewsPerAnime[i]))\n",
    "    mse = 0\n",
    "    for r in training_set:\n",
    "        prediction = alpha + betaU[r['user_id']] + betaI[r['anime_id']]\n",
    "        mse += (int(r['rating']) - prediction)**2\n",
    "    regularizer = 0\n",
    "    for u in betaU:\n",
    "        regularizer += betaU[u]**2\n",
    "    for i in betaI:\n",
    "        regularizer += betaI[i]**2\n",
    "    mse /= len(training_set)\n",
    "    return mse, mse + lamb*regularizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 136,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Fit with lambda = 1\n",
    "resetBeta()\n",
    "mse,objective = iterate(1)\n",
    "newMSE,newObjective = iterate(1)\n",
    "iterations = 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 137,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1.2850353201867877"
      ]
     },
     "execution_count": 137,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "newMSE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 138,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Objective after 3 iterations = 3096.0561687081877\n",
      "MSE after 3 iterations = 1.2819922007956852\n",
      "Objective after 4 iterations = 3086.39999410803\n",
      "MSE after 4 iterations = 1.2814807155769579\n",
      "Objective after 5 iterations = 3067.397715665469\n",
      "MSE after 5 iterations = 1.281273315669468\n",
      "Objective after 6 iterations = 3047.79334374342\n",
      "MSE after 6 iterations = 1.2811259643557653\n",
      "Objective after 7 iterations = 3029.4463805945174\n",
      "MSE after 7 iterations = 1.2809977920928621\n",
      "Objective after 8 iterations = 3012.656885845118\n",
      "MSE after 8 iterations = 1.2808800977957493\n",
      "Objective after 9 iterations = 2997.3812087609385\n",
      "MSE after 9 iterations = 1.28077059644888\n",
      "Objective after 10 iterations = 2983.5081164014746\n",
      "MSE after 10 iterations = 1.2806684015270227\n",
      "Objective after 11 iterations = 2970.920527115425\n",
      "MSE after 11 iterations = 1.2805729483998365\n",
      "Objective after 12 iterations = 2959.5083207548814\n",
      "MSE after 12 iterations = 1.2804837606069497\n",
      "Objective after 13 iterations = 2949.170222156615\n",
      "MSE after 13 iterations = 1.280400401197785\n",
      "Objective after 14 iterations = 2939.813430440721\n",
      "MSE after 14 iterations = 1.2803224633252408\n",
      "Objective after 15 iterations = 2931.3529031197354\n",
      "MSE after 15 iterations = 1.2802495681532522\n",
      "Objective after 16 iterations = 2923.7106705630467\n",
      "MSE after 16 iterations = 1.280181363601937\n",
      "Objective after 17 iterations = 2916.815228903326\n",
      "MSE after 17 iterations = 1.2801175229197923\n",
      "Objective after 18 iterations = 2910.601001116807\n",
      "MSE after 18 iterations = 1.2800577430950326\n",
      "Objective after 19 iterations = 2905.0078521457044\n",
      "MSE after 19 iterations = 1.280001743226594\n",
      "Objective after 20 iterations = 2899.9806480338366\n",
      "MSE after 20 iterations = 1.2799492629349616\n",
      "Objective after 21 iterations = 2895.468852523437\n",
      "MSE after 21 iterations = 1.2799000608524942\n",
      "Objective after 22 iterations = 2891.4261566500754\n",
      "MSE after 22 iterations = 1.2798539132090205\n",
      "Objective after 23 iterations = 2887.810138034271\n",
      "MSE after 23 iterations = 1.2798106125153563\n",
      "Objective after 24 iterations = 2884.5819472230105\n",
      "MSE after 24 iterations = 1.2797699663431146\n",
      "Objective after 25 iterations = 2881.7060188266287\n",
      "MSE after 25 iterations = 1.2797317961946948\n",
      "Objective after 26 iterations = 2879.149805458883\n",
      "MSE after 26 iterations = 1.279695936458798\n",
      "Objective after 27 iterations = 2876.883532681771\n",
      "MSE after 27 iterations = 1.279662233444324\n",
      "Objective after 28 iterations = 2874.8799733128767\n",
      "MSE after 28 iterations = 1.2796305444882148\n",
      "Objective after 29 iterations = 2873.1142395881398\n",
      "MSE after 29 iterations = 1.279600737130274\n",
      "Objective after 30 iterations = 2871.5635917911695\n",
      "MSE after 30 iterations = 1.2795726883513072\n",
      "Objective after 31 iterations = 2870.2072620695903\n",
      "MSE after 31 iterations = 1.279546283868651\n",
      "Objective after 32 iterations = 2869.0262922565425\n",
      "MSE after 32 iterations = 1.279521417485562\n",
      "Objective after 33 iterations = 2868.003384607069\n",
      "MSE after 33 iterations = 1.279497990489778\n",
      "Objective after 34 iterations = 2867.1227644427377\n",
      "MSE after 34 iterations = 1.2794759110978577\n",
      "Objective after 35 iterations = 2866.3700537754175\n",
      "MSE after 35 iterations = 1.2794550939416007\n",
      "Objective after 36 iterations = 2865.7321550517045\n",
      "MSE after 36 iterations = 1.2794354595936561\n",
      "Objective after 37 iterations = 2865.197144226784\n",
      "MSE after 37 iterations = 1.279416934128792\n",
      "Objective after 38 iterations = 2864.754172436309\n",
      "MSE after 38 iterations = 1.279399448718647\n",
      "Objective after 39 iterations = 2864.3933755919475\n",
      "MSE after 39 iterations = 1.2793829392571059\n",
      "Objective after 40 iterations = 2864.1057912777596\n",
      "MSE after 40 iterations = 1.2793673460141206\n",
      "Objective after 41 iterations = 2863.883282373143\n",
      "MSE after 41 iterations = 1.2793526133154516\n",
      "Objective after 42 iterations = 2863.718466871811\n",
      "MSE after 42 iterations = 1.279338689247061\n",
      "Objective after 43 iterations = 2863.604653408218\n",
      "MSE after 43 iterations = 1.2793255253813813\n",
      "Objective after 44 iterations = 2863.5357820398854\n",
      "MSE after 44 iterations = 1.2793130765246072\n",
      "Objective after 45 iterations = 2863.506369869348\n",
      "MSE after 45 iterations = 1.2793013004827343\n",
      "Objective after 46 iterations = 2863.5114611220006\n",
      "MSE after 46 iterations = 1.2792901578454274\n"
     ]
    }
   ],
   "source": [
    "while iterations < 10 or objective - newObjective > 0.0001:\n",
    "    mse, objective = newMSE, newObjective\n",
    "    newMSE, newObjective = iterate(1)\n",
    "    iterations += 1\n",
    "    print(\"Objective after \" + str(iterations) + \" iterations = \" + str(newObjective))\n",
    "    print(\"MSE after \" + str(iterations) + \" iterations = \" + str(newMSE))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 133,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def calcValidMSE():\n",
    "    validMSE = 0\n",
    "    for r in validation_set:\n",
    "        bu = 0\n",
    "        bi = 0\n",
    "        if r['user_id'] in betaU:\n",
    "            bu = betaU[r['user_id']]\n",
    "        if r['anime_id'] in betaI:\n",
    "            bi = betaI[r['anime_id']]\n",
    "        prediction = alpha + bu + bi\n",
    "        validMSE += (int(r['rating']) - prediction)**2\n",
    "\n",
    "    validMSE /= len(validation_set)\n",
    "    print(\"Validation MSE = \" + str(validMSE))\n",
    "    return validMSE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 132,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "defaultdict(<class 'float'>, {})\n"
     ]
    },
    {
     "ename": "TypeError",
     "evalue": "unsupported operand type(s) for +: 'collections.defaultdict' and 'float'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-132-340707fa1df9>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mcalcValidMSE\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m<ipython-input-131-f83a95383d22>\u001b[0m in \u001b[0;36mcalcValidMSE\u001b[0;34m()\u001b[0m\n\u001b[1;32m      9\u001b[0m             \u001b[0mbi\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mbetaI\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mr\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'anime_id'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m     10\u001b[0m         \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0malpha\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m---> 11\u001b[0;31m         \u001b[0mprediction\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0malpha\u001b[0m \u001b[1;33m+\u001b[0m \u001b[0mbu\u001b[0m \u001b[1;33m+\u001b[0m \u001b[0mbi\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     12\u001b[0m         \u001b[0mvalidMSE\u001b[0m \u001b[1;33m+=\u001b[0m \u001b[1;33m(\u001b[0m\u001b[0mint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mr\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'rating'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m-\u001b[0m \u001b[0mprediction\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m**\u001b[0m\u001b[1;36m2\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m     13\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mTypeError\u001b[0m: unsupported operand type(s) for +: 'collections.defaultdict' and 'float'"
     ]
    }
   ],
   "source": [
    "calcValidMSE()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Maximum betaU = 355 (2.3891606829652003\n",
      "Maximum betaI = 1657 (2.5913361219054227\n"
     ]
    }
   ],
   "source": [
    "betaUs = [(betaU[u], u) for u in betaU]\n",
    "betaIs = [(betaI[i], i) for i in betaI]\n",
    "betaUs.sort()\n",
    "betaIs.sort()\n",
    "\n",
    "print(\"Maximum betaU = \" + str(betaUs[-1][1]) + ' (' + str(betaUs[-1][0]))\n",
    "print(\"Maximum betaI = \" + str(betaIs[-1][1]) + ' (' + str(betaIs[-1][0]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def lambdaIteration(lambd, newMSE, newObjective):\n",
    "    iterations = 1\n",
    "    while (iterations < 10 or objective - newObjective > 0.0001) and not iterations > 100:\n",
    "        mse, objective = newMSE, newObjective\n",
    "        newMSE, newObjective = iterate(lambd)\n",
    "        iterations += 1\n",
    "        #print(\"Objective after \" + str(iterations) + \" iterations = \" + str(newObjective))\n",
    "        #print(\"MSE after \" + str(iterations) + \" iterations = \" + str(newMSE))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 149,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation MSE = 1.607817393727215\n"
     ]
    }
   ],
   "source": [
    "validMSE = 0\n",
    "for r in validation_set:\n",
    "    bu = 0\n",
    "    bi = 0\n",
    "    if r['user_id'] in betaU:\n",
    "        bu = betaU[r['user_id']]\n",
    "    if r['anime_id'] in betaI:\n",
    "        bi = betaI[r['anime_id']]\n",
    "    prediction = alpha + bu + bi\n",
    "    validMSE += (int(r['rating']) - prediction)**2\n",
    "\n",
    "validMSE /= len(validation_set)\n",
    "print(\"Validation MSE = \" + str(validMSE))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 197,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation MSE = 1.609951074270031\n",
      "Validation MSE = 1.632536446731577\n",
      "Validation MSE = 1.6692205392838553\n",
      "Validation MSE = 1.6463113508721245\n",
      "Validation MSE = 1.6380219498512807\n",
      "Validation MSE = 1.6300056531377174\n",
      "Validation MSE = 1.6186865382291677\n",
      "Validation MSE = 1.6089054168000279\n",
      "Validation MSE = 1.602443300681581\n",
      "Validation MSE = 1.5974148789221603\n",
      "Validation MSE = 1.5814022585722542\n",
      "Validation MSE = 1.607817393727215\n",
      "Validation MSE = 1.6818387645334538\n",
      "Validation MSE = 1.7801640611938188\n",
      "Validation MSE = 1.909824365129494\n"
     ]
    }
   ],
   "source": [
    "lambdas = [0.01, 0.1, 0.5, 0.75, 0.875, 1, 1.25, 1.5, 1.75, 2, 5, 10, 25, 50, 100]\n",
    "best_lambda = 0\n",
    "best_mse = 100000\n",
    "lambdaResult = []\n",
    "for lamb in lambdas:\n",
    "    resetBeta()\n",
    "    newMSE,newObjective = iterate(lamb)\n",
    "    lambdaIteration(lamb, newMSE, newObjective)\n",
    "    mse = calcValidMSE()\n",
    "    lambdaResult.append((lamb, mse))\n",
    "    if mse < best_mse:\n",
    "        best_mse = mse\n",
    "        best_lambda = lamb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 200,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.609951074270031\n",
      "1.632536446731577\n",
      "1.6692205392838553\n",
      "1.6463113508721245\n",
      "1.6380219498512807\n",
      "1.6300056531377174\n",
      "1.6186865382291677\n",
      "1.6089054168000279\n",
      "1.602443300681581\n",
      "1.5974148789221603\n",
      "1.5814022585722542\n",
      "1.607817393727215\n",
      "1.6818387645334538\n",
      "1.7801640611938188\n",
      "1.909824365129494\n"
     ]
    }
   ],
   "source": [
    "for(a, b) in lambdaResult:\n",
    "    print(b)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 186,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "resetBeta()\n",
    "newMSE,newObjective = iterate(best_lambda)\n",
    "lambdaIteration(best_lambda, newMSE, newObjective)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 151,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test MSE = 1.810081348394134\n"
     ]
    }
   ],
   "source": [
    "testMSE = 0\n",
    "for r in test_set:\n",
    "    bu = 0\n",
    "    bi = 0\n",
    "    if r['user_id'] in betaU:\n",
    "        bu = betaU[r['user_id']]\n",
    "    if r['anime_id'] in betaI:\n",
    "        bi = betaI[r['anime_id']]\n",
    "    prediction = alpha + bu + bi\n",
    "    testMSE += (int(r['rating']) - prediction)**2\n",
    "\n",
    "testMSE /= len(test_set)\n",
    "print(\"Test MSE = \" + str(testMSE))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 154,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training MSE = 0.0\n"
     ]
    }
   ],
   "source": [
    "trainingMSE = 0\n",
    "for r in training_set:\n",
    "    bu = 0\n",
    "    bi = 0\n",
    "    if r['user_id'] in betaU:\n",
    "        bu = betaU[r['user_id']]\n",
    "    if r['anime_id'] in betaI:\n",
    "        bi = betaI[r['anime_id']]\n",
    "    prediction = alpha + bu + bi\n",
    "    testMSE += (int(r['rating']) - prediction)**2\n",
    "\n",
    "trainingMSE /= len(training_set)\n",
    "print(\"Training MSE = \" + str(trainingMSE))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 188,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# feature for latent factor model\n",
    "\n",
    "def feature(r, threshhold):\n",
    "    a = alpha\n",
    "    bu = 0\n",
    "    bi = 0\n",
    "    if r['user_id'] in betaU:\n",
    "        bu = betaU[r['user_id']]\n",
    "    if r['anime_id'] in betaI:\n",
    "        bi = betaI[r['anime_id']]\n",
    "    prediction = alpha + bu + bi\n",
    "    \n",
    "    feat = [1]\n",
    "    feat.append(prediction)\n",
    "    #feat.append(jaccard_sim_user(r['user_id'],r['anime_id']))\n",
    "    feat.append(1 if jaccard_sim_user(r['user_id'],r['anime_id']) > threshhold else 0)\n",
    "    return feat\n",
    "        \n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 189,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# call function to build anime_user_dict and user_anime_dict\n",
    "\n",
    "anime_users_dict = get_anime_users()\n",
    "user_anime_dict = get_user_anime()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 190,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "feature() missing 1 required positional argument: 'threshhold'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-190-359b3ef2cf91>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0mlambdaIteration\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mbest_lambda\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mnewMSE\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mnewObjective\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m      6\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m----> 7\u001b[0;31m \u001b[0mX_train\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m[\u001b[0m\u001b[0mfeature\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0md\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0md\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mtraining_set\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      8\u001b[0m \u001b[0my_train\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m[\u001b[0m\u001b[0mfloat\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0md\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'rating'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0md\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mtraining_set\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m      9\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-190-359b3ef2cf91>\u001b[0m in \u001b[0;36m<listcomp>\u001b[0;34m(.0)\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0mlambdaIteration\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mbest_lambda\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mnewMSE\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mnewObjective\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m      6\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m----> 7\u001b[0;31m \u001b[0mX_train\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m[\u001b[0m\u001b[0mfeature\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0md\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0md\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mtraining_set\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      8\u001b[0m \u001b[0my_train\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m[\u001b[0m\u001b[0mfloat\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0md\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'rating'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0md\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mtraining_set\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m      9\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mTypeError\u001b[0m: feature() missing 1 required positional argument: 'threshhold'"
     ]
    }
   ],
   "source": [
    "# X = [feature_train(anime) for anime in beta_i]\n",
    "# y = [float(d['rating']) for d in training_set]\n",
    "resetBeta()\n",
    "newMSE,newObjective = iterate(best_lambda)\n",
    "lambdaIteration(best_lambda, newMSE, newObjective)\n",
    "\n",
    "X_train = [feature(d) for d in training_set]\n",
    "y_train = [float(d['rating']) for d in training_set]\n",
    "\n",
    "X_validation = [feature(d) for d in validation_set]\n",
    "y_validation = [float(d['rating']) for d in validation_set]\n",
    "\n",
    "X_test = [feature(d) for d in test_set]\n",
    "y_test = [float(d['rating']) for d in test_set]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import numpy\n",
    "\n",
    "theta, residuals, rank, s = numpy.linalg.lstsq(X_train,y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 191,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import math\n",
    "\n",
    "def mse(X, y, theta, size):\n",
    "    MSSum = 0.0\n",
    "    for i in range(0,size):\n",
    "        MSSum += numpy.square(int(y[i]) - numpy.dot(X[i], theta))\n",
    "    return MSSum / size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 192,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def trainAndValidate(threshold):\n",
    "    X_train = [feature(d, threshold) for d in training_set]\n",
    "    y_train = [float(d['rating']) for d in training_set] \n",
    "    \n",
    "    X_validation = [feature(d, threshold) for d in validation_set]\n",
    "    y_validation = [float(d['rating']) for d in validation_set]\n",
    "    valMSE = mse(X_validation,y_validation, theta, len(X_validation))\n",
    "    return valMSE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 195,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Threshold: 0.0 Error: 1.50887304386\n",
      "Threshold: 0.0075 Error: 1.50887304386\n",
      "Threshold: 0.015 Error: 1.50868440541\n",
      "Threshold: 0.0225 Error: 1.50810613212\n",
      "Threshold: 0.03 Error: 1.508058339\n",
      "Threshold: 0.0375 Error: 1.50832911652\n",
      "Threshold: 0.045 Error: 1.50871356807\n",
      "Threshold: 0.0525 Error: 1.50909127208\n",
      "Threshold: 0.06 Error: 1.50931522378\n",
      "Threshold: 0.0675 Error: 1.51064524351\n",
      "0.03\n",
      "1.508058339\n"
     ]
    }
   ],
   "source": [
    "best_thresh = 0\n",
    "best_err = 1000\n",
    "thresholds = [0.0075 * i for i in range(10)]\n",
    "thresholdResults = []\n",
    "for thresh in thresholds:\n",
    "    error = trainAndValidate(thresh)\n",
    "    print(\"Threshold: \" + str(thresh) + \" Error: \"+ str(error))\n",
    "    thresholdResults.append((thresh, error))\n",
    "    if error < best_err:\n",
    "        best_err = error\n",
    "        best_thresh = thresh\n",
    "\n",
    "print(best_thresh)\n",
    "print(best_err)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 196,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(0.0, 1.5088730438611639),\n",
       " (0.0075, 1.5088730438611639),\n",
       " (0.015, 1.5086844054061941),\n",
       " (0.0225, 1.5081061321185254),\n",
       " (0.03, 1.5080583389976012),\n",
       " (0.0375, 1.5083291165244339),\n",
       " (0.045, 1.5087135680694026),\n",
       " (0.0525, 1.5090912720770477),\n",
       " (0.06, 1.5093152237787846),\n",
       " (0.0675, 1.5106452435097131)]"
      ]
     },
     "execution_count": 196,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "thresholdResults"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 177,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation MSE is 1.50945589526\n",
      "Training MSE is 1.33095689358\n",
      "Test MSE is 1.6556327443\n",
      "variance is 2.26928253061\n",
      "\n",
      "RMSE is 1.2285991597169903\n"
     ]
    }
   ],
   "source": [
    "# Calculating MSE and variance\n",
    "\n",
    "print(\"Validation MSE is \" + str(mse(X_validation,y_validation, theta, len(X_validation))))\n",
    "print(\"Training MSE is \" + str(mse(X_train,y_train, theta, len(X_train))))\n",
    "print(\"Test MSE is \" + str(mse(X_test,y_test, theta, len(X_test))))\n",
    "print(\"variance is \" + str(numpy.var([int(d) for d in y_validation])))\n",
    "\n",
    "print(\"\\nRMSE is \"+ str(math.sqrt(mse(X_validation,y_validation, theta, len(X_validation)))))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Collaborative Filtering + Regression for rating prediction\n",
    "# Collaborative Filtering for watch prediction (in case we can't figure out how to do rating prediction)\n",
    "# Basic model for latent factor model\n",
    "# How to optimize\n",
    "\n",
    "### Graph\n",
    "# rating according to genre\n",
    "# rating according to types (Movie/OVA/TV Series)\n",
    "# rating according to number of members\n",
    "# Most popular word occuring in title\n",
    "# Average number of members by genres\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Collaborative Filtering + Regression for rating prediction\n",
    "# Collaborative Filtering for watch prediction (in case we can't figure out how to do rating prediction)\n",
    "# Basic model for latent factor model\n",
    "# How to optimize"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 155,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Rating prediction based on collaborative filtering + regression\n",
    "\n",
    "\n",
    "def get_anime_users():\n",
    "    #first get a dictionary of key: business user: set\n",
    "    anime_user_dict = {}\n",
    "    for review in training_set:\n",
    "        anime = review['anime_id']\n",
    "        user = review['user_id']\n",
    "        if anime in anime_user_dict:\n",
    "            user_set = anime_user_dict[anime]\n",
    "            user_set.add(user)\n",
    "        else:\n",
    "            user_set = set()\n",
    "            user_set.add(user)\n",
    "            anime_user_dict[anime] = user_set\n",
    "    return anime_user_dict\n",
    "\n",
    "def get_user_anime():\n",
    "    #first get a dictionary of key: business user: set\n",
    "    user_anime_dict = {}\n",
    "    for review in training_set:\n",
    "        anime = review['anime_id']\n",
    "        user = review['user_id']\n",
    "        if user in user_anime_dict:\n",
    "            anime_set = user_anime_dict[user]\n",
    "            anime_set.add(anime)\n",
    "        else:\n",
    "            anime_set = set()\n",
    "            anime_set.add(anime)\n",
    "            user_anime_dict[user] = anime_set\n",
    "    return user_anime_dict\n",
    "\n",
    "\n",
    "\n",
    "def jaccard_sim_user(check_user, check_anime):\n",
    "    #given a business, find the most similar business\n",
    "    max_sim = 0.0\n",
    "#     count = 0\n",
    "\n",
    "    if check_anime not in anime_users_dict: return False\n",
    "    else:\n",
    "        users = anime_users_dict[check_anime]\n",
    "        for user in users:\n",
    "            if user == check_user: continue\n",
    "            if check_user not in user_anime_dict: continue\n",
    "            current_user_anime = user_anime_dict[user]\n",
    "            check_user_anime = user_anime_dict[check_user]\n",
    "            intersect = current_user_anime.intersection(check_user_anime)\n",
    "            union = current_user_anime.union(check_user_anime)\n",
    "            # print(intersect)\n",
    "            # print(union)\n",
    "            similarity = float(len(intersect))/len(union)\n",
    "            if similarity > max_sim:\n",
    "                max_sim = similarity\n",
    "            #max_sim += similarity\n",
    "#             count += 1\n",
    "\n",
    "#      print(max_sim)\n",
    "    return max_sim\n",
    "\n",
    "#     if (max_sim > 0.059):\n",
    "#         return True\n",
    "#     else:\n",
    "#         return False\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# call function to build anime_user_dict and user_anime_dict\n",
    "\n",
    "anime_users_dict = get_anime_users()\n",
    "user_anime_dict = get_user_anime()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import numpy\n",
    "\n",
    "# feature based on collaborative filtering\n",
    "def feature(u,a):\n",
    "    feat = [1]\n",
    "    #feat.append(1 if jaccard_sim_user(u,a) > 0.01 else 0)\n",
    "    feat.append(jaccard_sim_user(u,a))\n",
    "#     if (similarity(u,a)):\n",
    "#         feat.append(1)\n",
    "#     else:\n",
    "#         feat.append(0)\n",
    "    return feat"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "X_train = [feature(d['user_id'],d['anime_id']) for d in training_set]\n",
    "y_train = [float(d['rating']) for d in training_set]\n",
    "X_validation = [feature(d['user_id'],d['anime_id']) for d in validation_set]\n",
    "y_validation = [float(d['rating']) for d in validation_set]\n",
    "theta, residuals, rank, s = numpy.linalg.lstsq(X_train,y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 7.70948912,  1.53688363])"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "theta"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import math\n",
    "\n",
    "def mse(X, y, theta, size):\n",
    "    MSSum = 0.0\n",
    "    for i in range(0,size):\n",
    "        MSSum += numpy.square(int(y[i]) - numpy.dot(X[i], theta))\n",
    "    return MSSum / size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation MSE is 2.29699162412\n",
      "Training MSE is 2.2622388855\n",
      "variance is 2.30704351556\n",
      "\n",
      "RMSE is 1.5155829321147043\n"
     ]
    }
   ],
   "source": [
    "# Calculating MSE and variance\n",
    "\n",
    "print(\"Validation MSE is \" + str(mse(X_validation,y_validation, theta, len(X_validation))))\n",
    "print(\"Training MSE is \" + str(mse(X_train,y_train, theta, len(X_train))))\n",
    "print(\"variance is \" + str(numpy.var([int(d) for d in y_validation])))\n",
    "\n",
    "print(\"\\nRMSE is \"+ str(math.sqrt(mse(X_validation,y_validation, theta, len(X_validation)))))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Watch prediction based on collaborative filtering\n",
    "\n",
    "\n",
    "import random\n",
    "\n",
    "anime_id_set = set()\n",
    "user_id_set = set()\n",
    "for l in rating_3:\n",
    "    anime_id_set.add(l['anime_id'])\n",
    "    user_id_set.add(l['user_id'])\n",
    "    \n",
    "visited_pair = []\n",
    "for l in validation_set:\n",
    "    visited_pair.append((l['user_id'], l['anime_id']))\n",
    "anime_id_list = list(anime_id_set)\n",
    "user_id_list = list(user_id_set)\n",
    "visited_pair = set(visited_pair)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# Build random pairs \n",
    "\n",
    "random_pair = []\n",
    "count = 0\n",
    "\n",
    "while(count < 75000):\n",
    "    randomIndex1 = random.randint(0, len(anime_id_set)-1)\n",
    "    randomIndex2 = random.randint(0, len(user_id_set)-1)\n",
    "    userid = user_id_list[randomIndex2]\n",
    "    animeid = anime_id_list[randomIndex1]\n",
    "    \n",
    "    if (userid,animeid) not in visited_pair:\n",
    "        temp_dict = {}\n",
    "        temp_dict['user_id'] = userid\n",
    "        temp_dict['anime_id'] = animeid\n",
    "    \n",
    "        random_pair.append(temp_dict)\n",
    "        count += 1\n",
    "        \n",
    "        \n",
    "# Combine random pairs with validation set to make complete validation set\n",
    "\n",
    "complete_validation_set = validation_set + random_pair"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Watch prediction\n",
    "\n",
    "def watch_prediction():\n",
    "    \n",
    "    true_pos = 0\n",
    "    true_neg = 0\n",
    "    \n",
    "    for l in validation_set:\n",
    "        u,a = l['user_id'], l['anime_id']\n",
    "        if jaccard_sim_user(u,a):\n",
    "            true_pos += 1\n",
    "            \n",
    "    for l in random_pair:\n",
    "        u,a = l['user_id'], l['anime_id']\n",
    "        if not jaccard_sim_user(u,a):\n",
    "            true_neg += 1\n",
    "            \n",
    "    accuracy = (true_pos + true_neg) / len(complete_validation_set)\n",
    "    print(\"Accuracy is \", accuracy)\n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy is  0.65856\n"
     ]
    }
   ],
   "source": [
    "watch_prediction()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# To-do List\n",
    "\n",
    "# Finish latent factor model with regresison\n",
    "# Try using both jaccard similarity and latent factor model\n",
    "# Writeup\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python [default]",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
