{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true,
    "scrolled": false
   },
   "source": [
    "import csv\n",
    "from collections import defaultdict\n",
    "\n",
    "toJson = open('anime.json', 'w')\n",
    "count = 0\n",
    "toJson.write('[')\n",
    "with open('anime.csv') as csvDataFile:\n",
    "    csvReader = csv.reader(csvDataFile)\n",
    "    for row in csvReader:\n",
    "        if row[0] == 'anime_id':\n",
    "            continue\n",
    "        \n",
    "        \n",
    "        genre_list = row[2].split(',')\n",
    "        genres = '['\n",
    "        for g in range(len(genre_list)):\n",
    "            genre = genre_list[g].replace(\" \", \"\")\n",
    "            genres += '\"'\n",
    "            genres += genre\n",
    "            if g != len(genre_list)-1:\n",
    "                genres += '\",'\n",
    "            else:\n",
    "                genres += '\"]'\n",
    "                \n",
    "        rating = row[5]\n",
    "        if rating == '':\n",
    "            rating = -1\n",
    "        \n",
    "        if (count != 0):\n",
    "            toJson.write(',\\n')\n",
    "        \n",
    "        toJson.write('{ \"anime_id\" : \"' + str(row[0]) + '\", \"name\" : \"' + str(row[1]) + '\", \"genre\" : '\n",
    "              + str(genres) + ', \"type\" : \"' + str(row[3]) + '\", \"episodes\" : \"'\n",
    "              + str(row[4]) + '\", \"rating\" : ' + str(rating) + ', \"members\" : ' + str(row[6]) + '}')\n",
    "        \n",
    "        count += 1\n",
    "    \n",
    "toJson.write(']')\n",
    "toJson.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import json\n",
    "\n",
    "rating = json.load(open('rating_200k.json'))\n",
    "animedata = json.load(open('anime.json'))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Make a train / validation set\n",
    "\n",
    "rating_filtered = []\n",
    "for entry in rating:\n",
    "    if (entry['rating'] != '-1'):\n",
    "        rating_filtered.append(entry)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Approach 2\n",
    "\n",
    "import random\n",
    "\n",
    "def scrambled(orig):\n",
    "    dest = orig[:]\n",
    "    random.shuffle(dest)\n",
    "    return dest\n",
    "\n",
    "rating_scrambled = scrambled(rating_filtered)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Approach 3\n",
    "\n",
    "rating_toModify = rating_filtered[:]\n",
    "\n",
    "current_user_id = 1\n",
    "rating_3 = []\n",
    "\n",
    "checknumber = 150000\n",
    "\n",
    "while(len(rating_toModify) > 3000):\n",
    "    \n",
    "    for j in range(0,len(rating_toModify)-1):\n",
    "\n",
    "        if j >= len(rating_toModify)-1:\n",
    "            break\n",
    "        \n",
    "        this_rating = rating_toModify[j]\n",
    "        current_user_id_str = str(current_user_id)\n",
    "        \n",
    "        if this_rating['user_id'] == current_user_id_str:\n",
    "\n",
    "            rating_3.append(this_rating)\n",
    "            rating_toModify.pop(j)\n",
    "            current_user_id += 1\n",
    "            \n",
    "        if int(this_rating['user_id']) > current_user_id:\n",
    "            current_user_id += 1\n",
    "            \n",
    "        \n",
    "\n",
    "    if current_user_id >= 2012:\n",
    "        current_user_id = 1\n",
    "    \n",
    "remaining = rating_toModify[:]\n",
    "rating_3 = rating_3 + remaining"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "rating_3 = rating_3[:150000]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "training_set = rating_3[:75000]\n",
    "validation_set = rating_3[75000:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "genre_by_anime = defaultdict(list)      # list of animes corresponding to certain genre\n",
    "\n",
    "for entry in animedata: \n",
    "    for genre in entry['genre']:\n",
    "        genre_by_anime[genre].append(entry['anime_id'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "anime_view_dict = defaultdict(list)     # list of users that watched certain anime\n",
    "\n",
    "for entry in rating:\n",
    "    anime_id = entry['anime_id']\n",
    "    user_id = entry['user_id']\n",
    "    anime_view_dict[anime_id].append(user_id)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "genres = set()    # set of all genres\n",
    "genreCount = defaultdict(int)     # count of each genre\n",
    "\n",
    "for entry in animedata:\n",
    "    for genre in entry['genre']:\n",
    "        genres.add(genre)\n",
    "        genreCount[genre] += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# train data \n",
    "\n",
    "from collections import defaultdict\n",
    "\n",
    "watched = defaultdict(set)\n",
    "rating_by_user = defaultdict(list)    # list of animes with rating that each user watched\n",
    "rating_by_anime = defaultdict(list)    # list of dictionary with anime as keys, and containing user and ratings\n",
    "\n",
    "\n",
    "for entry in training_set:\n",
    "    watched[entry['user_id']].add(entry['anime_id'])\n",
    "    \n",
    "    anime_dict = {}\n",
    "    if (entry['rating'] != '-1'):\n",
    "        anime_dict['anime_id'] = entry['anime_id']\n",
    "        anime_dict['rating'] = entry['rating']\n",
    "        rating_by_user[entry['user_id']].append(anime_dict)\n",
    "    \n",
    "    user_dict = {}\n",
    "    if (entry['rating'] != '-1'):\n",
    "        user_dict['rating'] = entry['rating']\n",
    "        user_dict['user_id'] = entry['user_id'] \n",
    "        rating_by_anime[entry['anime_id']].append(user_dict)\n",
    "    \n",
    "    \n",
    "    \n",
    "    \n",
    "    \n",
    "   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Calculating beta_u, beta_i"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "average_rating_by_user = defaultdict(float)\n",
    "\n",
    "for user in rating_by_user:\n",
    "    \n",
    "    animes = rating_by_user[user]\n",
    "    total = 0\n",
    "    count = 0\n",
    "    \n",
    "    for anime in animes:    \n",
    "        total += float(anime['rating'])\n",
    "        count += 1\n",
    "            \n",
    "    if count != 0:\n",
    "        average_rating_by_user[user] = total / count\n",
    "        \n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "beta_u = defaultdict(float)\n",
    "\n",
    "total = 0\n",
    "count = 0\n",
    "for user in average_rating_by_user:\n",
    "    total += average_rating_by_user[user]\n",
    "    count += 1\n",
    "    \n",
    "total_average_rating_byuser = total / count\n",
    "\n",
    "for user in average_rating_by_user:\n",
    "    beta_u[user] = average_rating_by_user[user] - total_average_rating_byuser"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "anime_average_rating = defaultdict(float)      # average rating of each anime\n",
    "\n",
    "for entry in animedata:\n",
    "    if (entry['rating'] != -1 and entry['rating'] != 0):\n",
    "        anime_average_rating[entry['anime_id']] = entry['rating']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "beta_i = defaultdict(float)\n",
    "\n",
    "total = 0\n",
    "count = 0\n",
    "for anime in anime_average_rating:\n",
    "    total += anime_average_rating[anime]\n",
    "    count += 1\n",
    "    \n",
    "total_average_rating_byanime = total / count\n",
    "\n",
    "for anime in anime_average_rating:\n",
    "    beta_i[anime] = anime_average_rating[anime] - total_average_rating_byanime"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "alpha = anime_average_rating   # average rating by anime\n",
    "beta_u  # how much does this user tend to rate animes above the mean?\n",
    "beta_i  # does this anime tend to receive higher ratings than others?\n",
    "print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {},
   "outputs": [],
   "source": [
    "def feature_train(this_anime):\n",
    "    a = alpha[this_anime]\n",
    "    bi = beta_i[this_anime]\n",
    "    feat = [1]\n",
    "    for entry in training_set:\n",
    "        bu = beta_u[entry['user_id']]\n",
    "        feat.append(a+bi+beta_u[user])\n",
    "        \n",
    "    return feat\n",
    "        \n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {},
   "outputs": [],
   "source": [
    "# X = [feature_train(anime) for anime in beta_i]\n",
    "# y = [float(d['rating']) for d in training_set]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# writeFile = open('ratingset_1.json', 'w')\n",
    "# for entry in rating_filtered:\n",
    "#     writeFile.write(str(entry))\n",
    "    \n",
    "# writeFile.close()\n",
    "\n",
    "# writeFile = open('ratingset_2.json', 'w')\n",
    "# for entry in rating_scrambled:\n",
    "#     writeFile.write(str(entry))\n",
    "    \n",
    "# writeFile.close()\n",
    "\n",
    "# writeFile = open('ratingset_3.json', 'w')\n",
    "# for entry in rating_3:\n",
    "#     writeFile.write(str(entry))\n",
    "    \n",
    "# writeFile.close()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Collaborative Filtering + Regression for rating prediction\n",
    "# Collaborative Filtering for watch prediction (in case we can't figure out how to do rating prediction)\n",
    "# Basic model for latent factor model\n",
    "# How to optimize\n",
    "\n",
    "### Graph\n",
    "# rating according to genre\n",
    "# rating according to types (Movie/OVA/TV Series)\n",
    "# rating according to number of members\n",
    "# Most popular word occuring in title\n",
    "# Average number of members by genres\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "japanese_stopwords = {\"a\", \"i\", \"u\", \"e\", \"o\", \"ka\", \"ki\", \"ku\", \"ke\", \"ko\", \"ga\", \"gi\", \"gu\", \"ge\", \"go\",\n",
    "                      \"sa\", \"si\", \"su\", \"se\", \"so\", \"za\", \"zi\", \"zu\", \"ze\", \"zo\",\n",
    "                        \"ta\", \"ti\",\"tsu\", \"te\", \"to\", \"da\", \"di\", \"du\", \"de\", \"do\", \"na\", \"no\", \"ni\",\"nu\", \"ne\",\n",
    "                      \"ha\", \"hi\", \"hu\", \"he\", \"ho\", \"ba\", \"bi\", \"bu\", \"be\", \"bo\", \"ma\", \"mi\", \"mu\", \"me\", \"mo\",\n",
    "                      \"ya\", \"yo\",\"yu\", \"ra\", \"ri\", \"ru\", \"re\", \"ro\", \"wa\", \"wo\", \"n\"}\n",
    "\n",
    "number = {\"1\",\"2\",\"3\",\"4\",\"5\",\"6\",\"7\",\"8\",\"9\"}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Most popular word occuring in title\n",
    "\n",
    "import string\n",
    "from nltk.stem.porter import *\n",
    "from nltk.corpus import stopwords\n",
    "\n",
    "ps = PorterStemmer()\n",
    "\n",
    "popWordDict = defaultdict(int)\n",
    "\n",
    "\n",
    "for entry in animedata:\n",
    "    title = ''.join([c for c in entry['name'].lower() if not c in string.punctuation])\n",
    "    for w in title.split():\n",
    "        if w not in stopwords.words('english') and w not in japanese_stopwords and w not in number:\n",
    "            popWordDict[w] += 1\n",
    "\n",
    "popWord = []\n",
    "for w in popWordDict:\n",
    "    popWord.append([popWordDict[w],w])\n",
    "popWord.sort()\n",
    "popWord.reverse()\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Average number of members by genres\n",
    "# Average ratings by genre\n",
    "\n",
    "average_member_by_genres = defaultdict(int)\n",
    "average_rating_by_genres = defaultdict(int)\n",
    "\n",
    "for entry in animedata:\n",
    "    members = entry['members']\n",
    "    ratings = entry['rating']\n",
    "    genres = []\n",
    "    for genre in entry['genre']:\n",
    "        average_member_by_genres[genre] += members\n",
    "        average_rating_by_genres[genre] += ratings\n",
    "        \n",
    "for genre in average_member_by_genres:\n",
    "    average_member_by_genres[genre] /=  genreCount[genre]\n",
    "    average_rating_by_genres[genre] /= genreCount[genre]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "typeCount = defaultdict(int)\n",
    "\n",
    "for entry in animedata:\n",
    "    typeCount[entry['type']] += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "arbg = open('average_rating_by_genres.csv', 'w')\n",
    "\n",
    "arbg.write(\"Genre\\tAverage Rating\\n\")\n",
    "for l in average_rating_by_genres:\n",
    "    if l != '':\n",
    "        arbg.write(l + \"\\t\"+ str(average_rating_by_genres[l]) + \"\\n\")\n",
    "        \n",
    "arbg.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "pw = open('popular_words.csv', 'w')\n",
    "\n",
    "pw.write(\"word\\tcount\\n\")\n",
    "for l in popWord:\n",
    "    pw.write(str(l[1]) + \"\\t\"+ str(l[0]) + \"\\n\")\n",
    "        \n",
    "pw.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "ambg = open('average_member_by_genres.csv', 'w')\n",
    "\n",
    "ambg.write(\"Genre\\tAverage Rating\\n\")\n",
    "for l in average_member_by_genres:\n",
    "    if l != '':\n",
    "        ambg.write(l + \"\\t\"+ str(average_member_by_genres[l]) + \"\\n\")\n",
    "        \n",
    "ambg.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Collaborative Filtering + Regression for rating prediction\n",
    "# Collaborative Filtering for watch prediction (in case we can't figure out how to do rating prediction)\n",
    "# Basic model for latent factor model\n",
    "# How to optimize"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "\n",
    "# somedict_anime = defaultdict(set)\n",
    "# somedict_user = defaultdict(set)\n",
    "\n",
    "# for l in training_set:\n",
    "#     anime, user = l['anime_id'], l['user_id']\n",
    "#     somedict_anime[user].add(anime)\n",
    "#     somedict_user[anime].add(user)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Rating prediction based on collaborative filtering + regression\n",
    "\n",
    "def get_anime_users():\n",
    "    #first get a dictionary of key: business user: set\n",
    "    anime_user_dict = {}\n",
    "    for review in training_set:\n",
    "        anime = review['anime_id']\n",
    "        user = review['user_id']\n",
    "        if anime in anime_user_dict:\n",
    "            user_set = anime_user_dict[anime]\n",
    "            user_set.add(user)\n",
    "        else:\n",
    "            user_set = set()\n",
    "            user_set.add(user)\n",
    "            anime_user_dict[anime] = user_set\n",
    "    return anime_user_dict\n",
    "\n",
    "def get_user_anime():\n",
    "    #first get a dictionary of key: business user: set\n",
    "    user_anime_dict = {}\n",
    "    for review in training_set:\n",
    "        anime = review['anime_id']\n",
    "        user = review['user_id']\n",
    "        if user in user_anime_dict:\n",
    "            anime_set = user_anime_dict[user]\n",
    "            anime_set.add(anime)\n",
    "        else:\n",
    "            anime_set = set()\n",
    "            anime_set.add(anime)\n",
    "            user_anime_dict[user] = anime_set\n",
    "    return user_anime_dict\n",
    "\n",
    "anime_users_dict = get_anime_users()\n",
    "user_anime_dict = get_user_anime()\n",
    "\n",
    "def jaccard_sim_user(check_user, check_anime):\n",
    "    #given a business, find the most similar business\n",
    "    max_sim = 0.0\n",
    "#     count = 0\n",
    "\n",
    "    if check_anime not in anime_users_dict: return False\n",
    "    else:\n",
    "        users = anime_users_dict[check_anime]\n",
    "        for user in users:\n",
    "            if user == check_user: continue\n",
    "            if check_user not in user_anime_dict: continue\n",
    "            current_user_anime = user_anime_dict[user]\n",
    "            check_user_anime = user_anime_dict[check_user]\n",
    "            intersect = current_user_anime.intersection(check_user_anime)\n",
    "            union = current_user_anime.union(check_user_anime)\n",
    "            # print(intersect)\n",
    "            # print(union)\n",
    "            similarity = float(len(intersect))/len(union)\n",
    "            if similarity > max_sim:\n",
    "                max_sim = similarity\n",
    "            #max_sim += similarity\n",
    "#             count += 1\n",
    "\n",
    "#      print(max_sim)\n",
    "    return max_sim\n",
    "\n",
    "#     if (max_sim > 0.059):\n",
    "#         return True\n",
    "#     else:\n",
    "#         return False\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import numpy\n",
    "\n",
    "def feature(u,a):\n",
    "    feat = [1]\n",
    "    #feat.append(1 if jaccard_sim_user(u,a) > 0.01 else 0)\n",
    "    feat.append(jaccard_sim_user(u,a))\n",
    "#     if (similarity(u,a)):\n",
    "#         feat.append(1)\n",
    "#     else:\n",
    "#         feat.append(0)\n",
    "    return feat\n",
    "\n",
    "\n",
    "\n",
    "X_train = [feature(d['user_id'],d['anime_id']) for d in training_set]\n",
    "y_train = [float(d['rating']) for d in training_set]\n",
    "X_validation = [feature(d['user_id'],d['anime_id']) for d in validation_set]\n",
    "y_validation = [float(d['rating']) for d in validation_set]\n",
    "theta, residuals, rank, s = numpy.linalg.lstsq(X_train,y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 7.70948912,  1.53688363])"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "theta"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation MSE is 2.29699162412\n",
      "Training MSE is 2.2622388855\n",
      "variance is 2.30704351556\n",
      "\n",
      "RMSE is 1.5155829321147043\n"
     ]
    }
   ],
   "source": [
    "import math\n",
    "\n",
    "def mse(X, y, theta, size):\n",
    "    MSSum = 0.0\n",
    "    for i in range(0,size):\n",
    "        MSSum += numpy.square(int(y[i]) - numpy.dot(X[i], theta))\n",
    "    return MSSum / size\n",
    "\n",
    "print(\"Validation MSE is \" + str(mse(X_validation,y_validation, theta, len(X_validation))))\n",
    "print(\"Training MSE is \" + str(mse(X_train,y_train, theta, len(X_train))))\n",
    "print(\"variance is \" + str(numpy.var([int(d) for d in y_validation])))\n",
    "\n",
    "print(\"\\nRMSE is \"+ str(math.sqrt(mse(X_validation,y_validation, theta, len(X_validation)))))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Watch prediction based on collaborative filtering\n",
    "\n",
    "anime_id_set = set()\n",
    "user_id_set = set()\n",
    "for l in rating_3:\n",
    "    anime_id_set.add(l['anime_id'])\n",
    "    user_id_set.add(l['user_id'])\n",
    "    \n",
    "visited_pair = []\n",
    "for l in validation_set:\n",
    "    visited_pair.append((l['user_id'], l['anime_id']))\n",
    "anime_id_list = list(anime_id_set)\n",
    "user_id_list = list(user_id_set)\n",
    "visited_pair = set(visited_pair)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import random\n",
    "\n",
    "random_pair = []\n",
    "count = 0\n",
    "\n",
    "while(count < 75000):\n",
    "    randomIndex1 = random.randint(0, len(anime_id_set)-1)\n",
    "    randomIndex2 = random.randint(0, len(user_id_set)-1)\n",
    "    userid = user_id_list[randomIndex2]\n",
    "    animeid = anime_id_list[randomIndex1]\n",
    "    \n",
    "#     print((userid, animeid))\n",
    "    if (userid,animeid) not in visited_pair:\n",
    "        temp_dict = {}\n",
    "        temp_dict['user_id'] = userid\n",
    "        temp_dict['anime_id'] = animeid\n",
    "    \n",
    "        random_pair.append(temp_dict)\n",
    "        count += 1\n",
    "# print(len(random_pair))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "complete_validation_set = validation_set + random_pair"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# complete_validation_set[74990:75010]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# def watch_prediction():\n",
    "    \n",
    "#     count = 0\n",
    "#     total = 0\n",
    "    \n",
    "#     for l in complete_validation_set:\n",
    "\n",
    "#         u,a = l['user_id'], l ['anime_id']\n",
    "        \n",
    "#         if jaccard_sim_user(u,a):\n",
    "#             count += 1\n",
    "#             total += 1\n",
    "            \n",
    "#         else:\n",
    "#             total += 1\n",
    "            \n",
    "#     print(\"Accuracy of this model is\")\n",
    "#     print(count * 1.0 / total)\n",
    "\n",
    "# watch_prediction()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy is  0.71658\n"
     ]
    }
   ],
   "source": [
    "def watch_prediction2():\n",
    "    \n",
    "    true_pos = 0\n",
    "    true_neg = 0\n",
    "    \n",
    "    for l in validation_set:\n",
    "        u,a = l['user_id'], l['anime_id']\n",
    "        if jaccard_sim_user(u,a):\n",
    "            true_pos += 1\n",
    "            \n",
    "    for l in random_pair:\n",
    "        u,a = l['user_id'], l['anime_id']\n",
    "        if not jaccard_sim_user(u,a):\n",
    "            true_neg += 1\n",
    "            \n",
    "    accuracy = (true_pos + true_neg) / len(complete_validation_set)\n",
    "    print(\"Accuracy is \", accuracy)\n",
    "    \n",
    "watch_prediction2()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# To-do List\n",
    "\n",
    "# Finish latent factor model with regresison\n",
    "# Try using both jaccard similarity and latent factor model\n",
    "# Writeup\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
